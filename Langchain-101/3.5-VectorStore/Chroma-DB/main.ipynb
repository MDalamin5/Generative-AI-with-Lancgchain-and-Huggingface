{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma\n",
    "\n",
    "`Chroma is a AI-native open source vector database focused on developer productivity and happiness. CHroma is licensed under apache 2.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a simple vectordb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('../FAISS-DB/speech.txt')\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1be3bbde450>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"gemma:2b\")\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example: For an object detection task, you could have:\\nTeacher 1 (YOLOv5): Focuses on fast bounding box detection.\\nTeacher 2 (EfficientNet): Focuses on object classification accuracy.\\nTeacher 3 (ResNet-50): Helps the student extract robust features from the image.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the task of YOLOv5 model?\"\n",
    "docs = vectordb.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in the disk\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embeddings, persist_directory=\"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: For an object detection task, you could have:\n",
      "Teacher 1 (YOLOv5): Focuses on fast bounding box detection.\n",
      "Teacher 2 (EfficientNet): Focuses on object classification accuracy.\n",
      "Teacher 3 (ResNet-50): Helps the student extract robust features from the image.\n"
     ]
    }
   ],
   "source": [
    "db2 = Chroma(persist_directory='./chroma_db', embedding_function=embeddings)\n",
    "docs = db2.similarity_search(query=query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '../FAISS-DB/speech.txt'}, page_content='Example: For an object detection task, you could have:\\nTeacher 1 (YOLOv5): Focuses on fast bounding box detection.\\nTeacher 2 (EfficientNet): Focuses on object classification accuracy.\\nTeacher 3 (ResNet-50): Helps the student extract robust features from the image.'),\n",
       "  3453.8228699758106),\n",
       " (Document(metadata={'source': '../FAISS-DB/speech.txt'}, page_content='Overview: In this project, the student model learns from multiple teacher models, each specializing in different aspects of the task. For example, one teacher could specialize in object detection, another in object classification, and a third in feature extraction.\\nNovelty: The key is designing a custom loss function that weights the contributions of each teacher differently based on the task at hand. This adaptive weighting would allow the student model to benefit from diverse perspectives.'),\n",
       "  3559.3035726328403),\n",
       " (Document(metadata={'source': '../FAISS-DB/speech.txt'}, page_content='Am if number no up period regard sudden better. Decisively surrounded all admiration and not you. Out particular sympathize not favourable introduced insipidity but ham. Rather number can and set praise. Distrusts an it contented perceived attending oh. Thoroughly estimating introduced stimulated why but motionless.'),\n",
       "  4242.445795323924),\n",
       " (Document(metadata={'source': '../FAISS-DB/speech.txt'}, page_content='Pasture he invited mr company shyness. But when shot real her. Chamber her observe visited removal six sending himself boy. At exquisite existence if an oh dependent excellent. Are gay head need down draw. Misery wonder enable mutual get set oppose the uneasy. End why melancholy estimating her had indulgence middletons. Say ferrars demands besides her address. Blind going you merit few fancy their.'),\n",
       "  4472.827602772152)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectordb.similarity_search_with_score(query=query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example: For an object detection task, you could have:\\nTeacher 1 (YOLOv5): Focuses on fast bounding box detection.\\nTeacher 2 (EfficientNet): Focuses on object classification accuracy.\\nTeacher 3 (ResNet-50): Helps the student extract robust features from the image.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retriever option\n",
    "retriver = vectordb.as_retriever()\n",
    "retriver.invoke(query)[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://js.langchain.com/v0.2/docs/integrations/vectorstores/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
