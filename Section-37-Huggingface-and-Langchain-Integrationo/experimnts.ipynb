{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">HuggingFace x Langchin: A new partner package in LangChain <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green\">HuggingFaceEndPoint <h1>\n",
    "<h2 style=\"color:red\">How to Access HuggingFace Models with API <h2>\n",
    "<h4 style=\"color:green\">There are also two ways to use this class. You can secify the model with the repoID parameter. Those endpoints use the serverless API, which is particulary beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=150, temperature=0.6, token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.6, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nThe process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nMachine learning is a science of creating algorithms and statistical models that computers use to perform tasks without explicit instructions. It is a method used to develop systems that can learn automatically to give accurate results. It’s one of the three main categories of artificial intelligence.\\n\\nThe goal of machine learning is to build algorithms that allow computers to learn from and make decisions or predictions based on data. It’s a way of creating systems that automatically improve with experience.\\n\\nMachine learning is a part of artificial intelligence (AI) based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. It’s a way to enable computers to learn automatically without being explicitly programmed.\\n\\nMachine learning is used in a wide range of applications, such as email filtering, detection of network intruders, and computer vision, where it is impractical to develop an algorithm specifically tailored to the task.\\n\\nMachine learning is used in a wide range of applications, including email filtering, network intrusion detection, and computer vision. It’s a way to enable computers to learn automatically without being explicitly programmed.\\n\\nMachine learning is a powerful tool that allows computers to learn from data, identify patterns, and make decisions or predictions based on that data. It’s a way to enable computers to learn and improve on their own, without being explicitly programmed.\\n\\nMachine learning is a subset of artificial intelligence (AI) that focuses on the development of computer programs that can access data and use it to learn for themselves. It’s a way to create systems that can automatically improve with experience, without the need for explicit programming.\\n\\nMachine learning is a method used to develop systems that can learn from data, identify patterns, and make decisions or predictions based on that data. It’s a way to enable computers to learn automatically without being explicitly programmed.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-9b-it', temperature=0.6, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='google/gemma-2-9b-it', client=<InferenceClient(model='google/gemma-2-9b-it', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-9b-it', timeout=120)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"google/gemma-2-9b-it\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=150, temperature=0.6, token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" studio\\n\\nGen-AI Studio is a comprehensive platform developed by **Google Cloud** that empowers developers and businesses to leverage the power of generative artificial intelligence (Gen-AI).\\n\\n**Key Features:**\\n\\n* **Model Development and Training:**\\n    * Provides tools and infrastructure for training custom Gen-AI models.\\n    * Supports various model architectures, including large language models (LLMs).\\n    * Offers pre-trained models for quick experimentation and deployment.\\n\\n* **Model Deployment and Management:**\\n    * Enables seamless deployment of Gen-AI models to production environments.\\n    * Provides tools for monitoring, managing, and scaling deployed models.\\n\\n* **Prompt Engineering:**\\n    * Offers guidance and tools for crafting effective prompts to elicit desired outputs from Gen-AI models.\\n    * Includes a library of pre-built prompts and templates.\\n\\n* **Data Management:**\\n    * Facilitates data ingestion, preprocessing, and management for Gen-AI model training and inference.\\n    * Supports various data formats and sources.\\n\\n* **Collaboration and Sharing:**\\n    * Enables collaboration among teams of developers and data scientists.\\n    * Allows for sharing of models, datasets, and prompt libraries.\\n\\n**Use Cases:**\\n\\n* **Text Generation:**\\n    * Creative writing\\n    * Content creation\\n    * Code generation\\n\\n* **Dialogue Systems:**\\n    * Chatbots\\n    * Virtual assistants\\n\\n* **Data Analysis and Summarization:**\\n    * Extracting insights from text data\\n    * Generating concise summaries\\n\\n* **Image and Video Generation:**\\n    * Creating realistic images and videos\\n\\n**Benefits:**\\n\\n* **Accelerated Development:** Streamlines the process of building and deploying Gen-AI applications.\\n* **Improved Accuracy and Performance:** Access to pre-trained models and advanced training techniques.\\n* **Scalability and Reliability:**\\n    * Cloud-based infrastructure ensures scalability and reliability.\\n* **Collaboration and Innovation:**\\n    * Fosters collaboration and innovation within development teams.\\n\\n\\n\\nLet me know if you'd like more details on any specific aspect of Gen-AI Studio!\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is gen-ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\nQuestion:{question}\\nAnswer:Lets things step by step\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets things step by step\n",
    "\"\"\"\n",
    "\n",
    "prompt=PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is ai',\n",
       " 'text': '* **What is Intelligence?**\\n\\nIntelligence is the ability to learn, understand, and apply knowledge to solve problems and make decisions. Humans are intelligent because we can reason, think critically, adapt to new situations, and create.\\n\\n* **What is Artificial?**\\n\\nArtificial means \"made by humans\" or \"not natural.\" \\n\\n* **Bringing it Together: AI**\\n\\nArtificial intelligence (AI) is the field of computer science that aims to create machines that can perform tasks that typically require human intelligence.  \\n\\n**Think of it like this:**\\n\\nImagine you\\'re teaching a dog a new trick. You show it what to do, give it rewards when it gets it right, and correct it when it makes mistakes. Over time, the dog learns the trick.\\n\\nAI works in a similar way.  We \"train\" computers by giving them massive amounts of data and algorithms (sets of instructions). The computer learns patterns and relationships in the data, and uses that knowledge to make predictions or decisions.\\n\\n**Examples of AI:**\\n\\n* **Self-driving cars:** AI helps cars \"see\" their surroundings and make decisions about how to drive safely.\\n* **Virtual assistants (like Siri or Alexa):** AI allows these assistants to understand your voice commands and respond appropriately.\\n* **Recommendation systems (on Netflix, Amazon, etc.):** AI analyzes your past behavior to suggest movies, products, or music you might like.\\n* **Medical diagnosis:** AI can help doctors analyze medical images and identify potential diseases.\\n\\n\\n\\nLet me know if you have any other questions!\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm, prompt=prompt)\n",
    "llm_chain.invoke('what is ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\torchGPU\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")\n",
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
