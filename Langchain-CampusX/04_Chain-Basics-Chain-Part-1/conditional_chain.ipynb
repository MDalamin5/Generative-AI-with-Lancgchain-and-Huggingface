{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=ChatGroq(groq_api_key=groq_api_key,model_name=\"qwen-2.5-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template=\"Classify the sentiment of the following feedback text into positive or negative \\n{feedback}\",\n",
    "    input_variables=['feedback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the feedback text \"This is a terrible smartphone\" is negative.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_chain = prompt1 | model | parser\n",
    "classifier_chain.invoke(\"This is a terrible smartphone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Apply PydanticOutputParser: Use structured output parser***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *My schema output class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')\n",
    "   \n",
    "   \n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"Classify the sentiment of the following feedback text into positive or negative \\n{feedback} \\n{format_instruction}\",\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={\n",
    "        'format_instruction': parser2.get_format_instructions()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(sentiment='negative')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_chain = prompt2 | model | parser2\n",
    "response = classifier_chain.invoke(\"This is a terrible smartphone\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_chain.invoke(\"This is a good smartphone\").sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Now Build the conditional Branch***\n",
    "\n",
    "`branch_chain = RunnableBranch(\n",
    "    ('condition', 'chain1'),\n",
    "    ('condition', 'chain2'),\n",
    "    'default'\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_pos = PromptTemplate(\n",
    "    template=\"Write the appropriate response to this positive feedback\\n{feedback}\",\n",
    "    input_variables=['feedback']\n",
    ")\n",
    "\n",
    "prompt_neg = PromptTemplate(\n",
    "    template=\"Write the appropriate response to this negative feedback\\n{feedback}\",\n",
    "    input_variables=['feedback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment == 'positive', prompt_pos | model | parser),\n",
    "    (lambda x:x.sentiment == 'negative', prompt_neg | model | parser),\n",
    "    RunnableLambda(lambda x: \"Could not find any king of sentiment\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = classifier_chain | branch_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively respond to negative feedback, it's important to show empathy, understanding, and a willingness to address the issues raised. Here's a general approach you could take:\n",
      "\n",
      "---\n",
      "\n",
      "Thank you very much for sharing your feedback with us. We truly appreciate you taking the time to let us know about your experience. We're sorry to hear that you've had a negative experience and we want to assure you that we are here to help resolve the issues you've mentioned.\n",
      "\n",
      "Could you please provide us with more details about the specific problems you encountered? This will help us to address your concerns more effectively. We are committed to improving and ensuring that all our users have a positive experience.\n",
      "\n",
      "Thank you again for bringing this to our attention. We value your input and look forward to making things right for you.\n",
      "\n",
      "---\n",
      "\n",
      "This response acknowledges the user's feelings and indicates a willingness to take action, which can help in turning a negative experience into a more positive one.\n"
     ]
    }
   ],
   "source": [
    "response = final_chain.invoke(\n",
    "    {\n",
    "        'feedback': \"This is a terrible phone\"\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's wonderful to hear! If there's anything else you need or if you want to share more about what you enjoyed, feel free to let me know. Thank you for your positive feedback!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        'feedback': \"This is a good phone and grate camera.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+----------------------+   \n",
      "| PydanticOutputParser |   \n",
      "+----------------------+   \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "        +--------+         \n",
      "        | Branch |         \n",
      "        +--------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
