{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableSequence, RunnableParallel, RunnableLambda, RunnableBranch\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model= ChatGroq(groq_api_key=groq_api_key,model_name=\"qwen-2.5-32b\")\n",
    "model2= ChatGroq(groq_api_key=groq_api_key,model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='Generate a details report about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Summarize the following text \\n{text}',\n",
    "    input_variables=['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runnable Lambda\n",
    "def word_counter(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_gen_chain = RunnableSequence(prompt, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x: len(x.split()) > 100 , RunnableSequence(prompt2, model2, parser)),\n",
    "    RunnablePassthrough()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableSequence(report_gen_chain, branch_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  +-------------+    \n",
      "  | PromptInput |    \n",
      "  +-------------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+----------------+   \n",
      "| PromptTemplate |   \n",
      "+----------------+   \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +----------+     \n",
      "    | ChatGroq |     \n",
      "    +----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+-----------------+  \n",
      "| StrOutputParser |  \n",
      "+-----------------+  \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +--------+       \n",
      "    | Branch |       \n",
      "    +--------+       \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "  +--------------+   \n",
      "  | BranchOutput |   \n",
      "  +--------------+   \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = final_chain.invoke(\n",
    "    {\n",
    "        'topic': \"Machine Learning\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the text:\n",
      "\n",
      "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that enables computers to perform tasks without explicit instructions by relying on patterns and inference. ML has revolutionized various industries, including healthcare, finance, transportation, and entertainment.\n",
      "\n",
      "The text covers the following core concepts and definitions:\n",
      "\n",
      "* Supervised Learning: training a model on a dataset with input and output variables\n",
      "* Unsupervised Learning: training a model on data without labeled responses\n",
      "* Reinforcement Learning: training a model to make decisions through trial and error\n",
      "\n",
      "Key techniques and algorithms mentioned include:\n",
      "\n",
      "* Linear Regression\n",
      "* Decision Trees\n",
      "* Support Vector Machines (SVM)\n",
      "* Neural Networks\n",
      "* Random Forest\n",
      "\n",
      "Applications of ML include:\n",
      "\n",
      "* Healthcare: predicting patient diagnoses, drug discovery, and personalized medicine\n",
      "* Finance: fraud detection, credit scoring, and algorithmic trading\n",
      "* Marketing: personalized marketing, customer segmentation, and churn prediction\n",
      "* Transportation: self-driving cars, route optimization, and predictive maintenance\n",
      "\n",
      "Challenges in ML include:\n",
      "\n",
      "* Data Quality: ensuring accurate, complete, and relevant data\n",
      "* Overfitting and Underfitting: avoiding models that are too complex or too simple\n",
      "* Bias and Fairness: avoiding models that perpetuate or amplify societal biases\n",
      "\n",
      "Future trends in ML include:\n",
      "\n",
      "* Edge Computing: moving computation closer to the data source\n",
      "* Explainability and Transparency: developing models that can explain their decisions\n",
      "* Quantum Machine Learning: exploring the potential of quantum computing to accelerate ML algorithms\n",
      "\n",
      "The conclusion emphasizes the rapid evolution of ML, its vast potential across industries, and the need for robust, ethical, and efficient ML solutions to drive innovation and improve decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
