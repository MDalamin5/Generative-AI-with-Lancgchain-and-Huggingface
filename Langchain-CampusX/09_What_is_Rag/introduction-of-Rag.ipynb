{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c4d270",
   "metadata": {},
   "source": [
    "## ***Introduction Of Rag-Conceptual Session***\n",
    "\n",
    "### *Why*\n",
    "- LLM storing knowledge is called parametric knowledge\n",
    "#### 3 Situation LLM can not give proper result\n",
    "- Recent data\n",
    "- Privet Data\n",
    "- Hallucination Problem\n",
    "\n",
    "### Solved by \n",
    "- Fine Tuning on domain Specific data\n",
    "    - Super vised Fine tuning: Prompt and output\n",
    "- Continue pre-train unsupervised\n",
    "- RLHF\n",
    "- LoRA\n",
    "-QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee25d27",
   "metadata": {},
   "source": [
    "### ***In-context Learning***\n",
    "- is a core capability of LLM like gpt3,4, Claude and Llama where the model learns to solve a task purely by seeing example in the prompt without updating its weights\n",
    "- Few shot prompt, COT-Prompt\n",
    "- Large model has auto capability of in-context learning\n",
    "- [More about in-context learning](https://arxiv.org/pdf/2005.14165)\n",
    "- parametric knowledge\n",
    "- in-context learning enhance is RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7afe2",
   "metadata": {},
   "source": [
    "# ***RAG***\n",
    "- Indexing - Data creation technique\n",
    "- Retrieval - similarity chunk searching extraction\n",
    "- Augmentation - user query and context add and create new prompt is augmentation\n",
    "- Generation - LLM generate the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69344b3f",
   "metadata": {},
   "source": [
    "## *Indexing*\n",
    "- Indexing is the process of preparing our knowledge base so that it can efficiently searched at query time. This steps consists of 4 sub-steps.\n",
    "1. Document Ingestion: Load the source knowledge into Memory\n",
    "    - pdf, or any data source get into the memory\n",
    "2. Text Chunking\n",
    "3. Vector Embedding\n",
    "4. Stor in vectorDB and create a vector Store as Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f102164f",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "query + prompt + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40960ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question only from the provided context.\n",
    "If the context is insufficient, just say you don't know.\n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
