{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022A519BEE70>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022A519BF8F0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Al Amin,\\n\\nIt's nice to meet you!  North South University's ECE department is well-regarded, and CSE is a fascinating field. \\n\\nWhat are you most interested in learning about within CSE?  Are you working on any interesting projects right now?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 32, 'total_tokens': 93, 'completion_time': 0.110909091, 'prompt_time': 0.000328589, 'queue_time': 0.014129028, 'total_time': 0.11123768}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bbd1cb91-05b5-4528-ab4d-cf05b0dea760-0', usage_metadata={'input_tokens': 32, 'output_tokens': 61, 'total_tokens': 93})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is Al Amin and i'm student of North South University ECE department and majoring in CSE.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Al Amin and you are a student at North South University. ðŸ˜Š \\n\\nIs there anything else I can help you with?  Perhaps you have a question about CSE or need help brainstorming project ideas?  I'm here to assist!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 109, 'total_tokens': 163, 'completion_time': 0.098181818, 'prompt_time': 0.003349896, 'queue_time': 0.011802552000000001, 'total_time': 0.101531714}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8396f34d-7012-4734-8b95-927322bb351c-0', usage_metadata={'input_tokens': 109, 'output_tokens': 54, 'total_tokens': 163})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "    HumanMessage(content=\"Hi, my name is Al Amin and i'm student of North South University ECE department and majoring in CSE.\"),\n",
    "    AIMessage(content=\"Hello Al Amin,\\n\\nIt's nice to meet you!  North South University's ECE department is well-regarded, and CSE is a fascinating field. \\n\\nWhat are you most interested in learning about within CSE?  Are you working on any interesting projects right now?\\n\"),\n",
    "    HumanMessage(content=\"What is my name and university name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History\n",
    "**We can use a Message History class to wrap our model and make it stateful. This will keep trak of inputs and outputs of the model, and store them in some datstore. Future interactions will then load thosse messages and pass them into the chain as part of the input. Let's see how to use this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Al Amin! \\n\\nIt's nice to meet you.  So you're studying Computer Science and Engineering (CSE) at North South University, even though you're in the ECE department? That's interesting!  \\n\\nDo you find the ECE background helpful for your CSE studies, or are they quite distinct?  \\n\\nI'm curious to hear more about your experience.  ðŸ˜Š  \\n\\n\\n\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Al Amin and i'm student of North South University ECE department and majoring in CSE.\"),\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your name is Al Amin, you are a student at North South University, and you are in the ECE department, majoring in CSE.  \\n\\nIs there anything else I can help you with? ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 309, 'total_tokens': 355, 'completion_time': 0.083636364, 'prompt_time': 0.010005537, 'queue_time': 0.00548761, 'total_time': 0.093641901}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a05f06d5-05da-4851-8730-a9e093133c23-0', usage_metadata={'input_tokens': 309, 'output_tokens': 46, 'total_tokens': 355})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name and university name and department also?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"session_id\": \"chat2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Khan! It's nice to meet you. ðŸ˜Š \\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 254, 'total_tokens': 279, 'completion_time': 0.045454545, 'prompt_time': 0.010037847, 'queue_time': 0.0037518029999999997, 'total_time': 0.055492392}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5c6ad215-e1ef-4879-9439-dba1b509df98-0', usage_metadata={'input_tokens': 254, 'output_tokens': 25, 'total_tokens': 279})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey, my name is khan\")],\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Khan!  \\n\\nIs there anything else I can help you with? ðŸ¤” ðŸ˜„  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 292, 'total_tokens': 315, 'completion_time': 0.041818182, 'prompt_time': 0.011475091, 'queue_time': 0.0032413289999999994, 'total_time': 0.053293273}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-aab9f66e-8520-4e79-8312-6d889e4e340b-0', usage_metadata={'input_tokens': 292, 'output_tokens': 23, 'total_tokens': 315})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"tell me my name!!\")],\n",
    "    config=config2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template\n",
    "\n",
    "**Prompt Templates help to trun raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the llm. Let's now make tha a bit more complicated. First, lets add in a system message with some custom instructions (but stilltaking messages as input). Next, we'll add in more input besides just the messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the question to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "        \n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
